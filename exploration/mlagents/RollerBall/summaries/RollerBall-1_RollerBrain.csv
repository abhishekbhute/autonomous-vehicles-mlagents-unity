Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
10000,1.4187682,0.0002970003,0.55263305,0.5848861283643892,0.5848861283643892,9.228778467908903,0.08592794,0.24329515
20000,1.4199601,0.00029100032,0.93107224,0.9556451612903226,0.9556451612903226,6.933064516129032,0.01749682,0.23948267
30000,1.4179252,0.00028500034,0.9656003,0.9887719298245614,0.9887719298245614,5.910877192982456,0.007530169,0.25148174
40000,1.4235955,0.00027900032,0.96016157,0.9882955376737381,0.9882955376737381,6.164594001463057,0.0064928667,0.24268003
