Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length
10000,1.4189383,0.00029400064,-0.25653693,19.748092078293364,19.748092103283852,202.14583333333334
20000,1.4189383,0.0002820006,-0.22745067,26.954306228955588,26.954305845830177,209.95555555555555
30000,1.4189383,0.00027000063,-0.2272287,29.054673253273478,29.05467336138292,200.18367346938774
40000,1.4189383,0.00025800063,-0.18212542,29.343137832320465,29.343137468306384,199.3877551020408
50000,1.4189383,0.00024600068,-0.2205418,28.693705758269953,28.693705700337887,196.91836734693877
60000,1.4189383,0.00023400063,-0.1995081,31.595681810130674,31.595682231088478,200.9375
70000,1.4189383,0.00022200064,-0.27018705,23.921376129414174,23.92137588132569,208.91489361702128
