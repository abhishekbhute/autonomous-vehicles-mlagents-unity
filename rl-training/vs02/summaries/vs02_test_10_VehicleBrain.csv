Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
10000,1.0976633,9.990001e-05,0.39780918,168.51592426747084,168.5159239694476,568.4375,48.259842,0.8590818
20000,1.088239,9.970001e-05,1.2437664,167.926224604249,167.92622653068975,606.4375,47.33204,0.8845668
30000,1.0852907,9.950001e-05,2.374174,172.188774228096,172.18877456556348,575.7058823529412,48.042976,0.86566436
40000,1.0873992,9.930001e-05,3.0870543,116.89165703246468,116.89165624858518,503.0,47.99137,0.9185756
