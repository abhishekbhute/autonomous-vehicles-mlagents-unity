Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
10000,1.0985532,9.990005e-05,0.37138334,153.74524813890457,153.74524819627405,806.5,41.487858,0.8350441
20001,1.0982798,9.970004e-05,1.2995361,197.8246404849566,197.8246395777051,814.6153846153846,37.380688,0.81023675
30001,1.0941918,9.950002e-05,3.6836228,200.8137223294803,200.8137229649084,685.0,34.283367,0.83585393
40000,1.0911425,9.9300036e-05,4.385665,174.00699938138325,174.0069995611906,585.6,31.227398,0.8124817
50000,1.086547,9.910005e-05,5.0066967,162.40880853599973,162.4088084341751,542.9444444444445,29.532963,0.7828736
60000,1.074819,9.890005e-05,6.974637,181.6071775039037,181.60718022386234,634.7333333333333,33.99349,0.7824856
70001,1.0652046,9.870004e-05,7.1400256,238.41181032474225,238.4118116962222,767.8461538461538,34.745445,0.7357294
80000,1.0710983,9.850004e-05,10.076076,194.92743376585153,194.92743447594918,753.9230769230769,38.989906,0.7785891
90001,1.0561588,9.830004e-05,15.5937805,102.6899293096442,102.68993013234515,483.1578947368421,61.63993,0.9433082
100000,1.029443,9.810004e-05,15.938387,95.97627129338004,95.97627134079283,444.8636363636364,60.525543,0.9609774
110002,1.0324944,9.7900025e-05,14.818941,97.5359824612027,97.53598201416787,459.0952380952381,47.799034,0.9471407
120000,1.0288535,9.770003e-05,12.554361,103.70233660274081,103.70233819716506,516.3888888888889,36.060043,0.86823845
130000,1.0345275,9.750005e-05,9.922336,104.30838706716895,104.3083880264312,615.625,34.39446,0.8542901
