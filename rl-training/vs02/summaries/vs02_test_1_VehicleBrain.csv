Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Curiosity Value Estimate,Policy/Extrinsic Reward,Policy/Curiosity Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss,Losses/Curiosity Forward Loss,Losses/Curiosity Inverse Loss
10000,1.097179,9.990001e-05,0.22475745,-0.012678821,215.372088432312,3.2187855324242265,215.37208675816655,875.1,23.810204,0.8474889,0.2162802,1.0979582
20000,1.0964353,9.970001e-05,1.5519388,0.069475025,266.9035264161917,0.5354302450924968,266.90352705006416,782.9230769230769,26.831213,0.79137725,0.03922815,1.0946127
30000,1.0915896,9.950001e-05,2.188714,-0.0015318823,174.4419387380282,0.8609516193488768,174.44194074658057,763.1666666666666,25.3146,0.81777173,0.03803095,1.0889186
