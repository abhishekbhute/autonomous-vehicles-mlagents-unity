Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length,Losses/Value Loss,Losses/Policy Loss
10000,1.0983979,9.990001e-05,-0.08704526,200.42038202285767,200.420383291319,1136.625,44.124016,0.84626293
20000,1.0980512,9.970001e-05,0.5709447,236.01665249798032,236.01665202445454,1138.111111111111,43.259018,0.82142144
30000,1.0959178,9.950001e-05,2.925197,240.01111030578613,240.01110802048987,825.2727272727273,35.307453,0.81496716
40000,1.0941514,9.930001e-05,3.3241186,262.9562856621212,262.95628601478205,1092.6666666666667,42.11333,0.77269924
50000,1.0972636,9.9100005e-05,3.2379227,210.0047136677636,210.00471206092172,1056.0,39.42237,0.8275579
60000,1.08111,9.890001e-05,6.054456,255.23703545873815,255.23703650181943,923.5454545454545,39.81187,0.80731803
70000,1.0698359,9.87e-05,4.519088,310.0894050523639,310.0894088288769,1194.125,33.724316,0.8233789
80000,1.0745863,9.850001e-05,5.706615,332.65081159273785,332.65081311596765,1068.4444444444443,35.79698,0.7339275
90000,1.0780549,9.830001e-05,7.800726,287.94498909844293,287.9449928899606,1007.0,31.878036,0.7721649
100000,1.0777737,9.810001e-05,8.127971,323.8269053366449,323.82690432336597,1141.5555555555557,37.21267,0.7572
110000,1.0907098,9.790001e-05,8.773054,224.12836693633687,224.1283691891215,881.9090909090909,36.65299,0.75650704
120000,1.0932245,9.770001e-05,6.545236,113.90204573529107,113.90204509028366,722.3571428571429,35.76158,0.8331157
130000,1.0902606,9.750001e-05,6.767259,108.83883297901887,108.83883395676429,716.0,33.504982,0.80944365
140000,1.085217,9.7300006e-05,1.6826655,33.47931350270907,33.47931133210659,797.5833333333334,35.78697,0.8185752
