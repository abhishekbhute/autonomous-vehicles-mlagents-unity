Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length
1000,1.4189383,0.00029940062,-0.012266712,145.40000104904175,145.4000039100647,304.0
2000,1.4189383,0.0002982006,-0.028851047,161.46667353312174,161.46667047341666,355.6666666666667
3000,1.4189383,0.00029700057,-0.026435366,193.4000105857849,193.4000042527914,435.0
4000,1.4189383,0.00029580062,-0.026998278,159.73333994547525,159.73333712418875,351.0
5000,1.4189383,0.0002946006,-0.045951962,143.86667116483054,143.86667005221048,317.6666666666667
6000,1.4189383,0.0002934006,-0.074634016,209.4000129699707,209.40000435709953,476.0
7000,1.4189383,0.00029220062,-0.06665021,158.40001106262207,158.400003105402,370.0
8000,1.4189383,0.00029100062,-0.03562303,168.2000130812327,168.20000391205153,371.6666666666667
9000,1.4189383,0.0002898006,-0.023863526,128.26667308807373,128.26666965087256,284.6666666666667
10000,1.4189383,0.00028860063,-0.080355525,218.30001085996628,218.30000449717045,500.5
