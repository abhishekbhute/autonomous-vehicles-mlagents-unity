Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Losses/Value Loss,Losses/Policy Loss,Policy/Extrinsic Reward,Environment/Cumulative Reward,Environment/Episode Length
1000,1.4179422,0.00029940062,0.3288741,124.996704,0.2533146,-13.0,-13.0,353.5
2000,1.4188708,0.0002982006,-2.219613,110.01657,0.23955837,-13.333333333333334,-13.333333333333334,328.6666666666667
3000,1.4205508,0.00029700057,-7.6909513,71.870285,0.24173263,-85.0,-85.0,426.5
4000,1.4213504,0.00029580062,-5.1075077,134.65004,0.22717248,10.625,10.625,271.0
5000,1.4262642,0.0002946006,-5.9199586,119.514175,0.23648688,15.5,15.5,247.0
6000,1.4228613,0.0002934006,-9.909259,103.428085,0.2616745,26.833333333333332,26.833333333333332,252.0
7000,1.4191753,0.00029220062,-9.756291,107.778885,0.25729784,23.0,23.0,247.0
8000,1.4170023,0.00029100062,-16.337303,132.58691,0.23782758,21.5,21.5,250.75
9000,1.414869,0.0002898006,-16.614992,99.933174,0.25451675,23.5,23.5,247.0
10000,1.4125804,0.00028860063,-16.869635,132.98639,0.23557511,-4.5,-4.5,247.0
11000,1.4100058,0.00028740062,-17.001402,107.23952,0.23360035,15.5,15.5,247.0
12000,1.4102099,0.00028620064,-17.101488,78.0526,0.24058107,7.0,7.0,247.0
